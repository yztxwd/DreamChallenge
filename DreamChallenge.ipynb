{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dream Challenge Model Prototye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import synapseclient \n",
    "import synapseutils \n",
    "\n",
    "syn = synapseclient.Synapse() \n",
    "syn.login('yztxwd@gmail.com','9zqqW9Jy5QhRFeS') \n",
    "synapseutils.syncFromSynapse(syn, 'syn30026233', './data/')\n",
    "synapseutils.syncFromSynapse(syn, 'syn28469146', './data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_table(\"./data/train_sequences.txt\", header=None, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_full = pd.read_table('./data/train_sequences.txt', header=None, names=['seq', 'target'], dtype={'seq':str, 'target':np.float32})\n",
    "df_train, df_remain = train_test_split(df_full, test_size=0.2, random_state=1)\n",
    "df_val, df_test = train_test_split(df_remain, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = DreamChallengeDataset(df_train.reset_index(), transform=DNA2OneHot())\n",
    "dataset_val = DreamChallengeDataset(df_val.reset_index(), transform=DNA2OneHot())\n",
    "dataset_test = DreamChallengeDataset(df_test.reset_index(), transform=DNA2OneHot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seq</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4105474</td>\n",
       "      <td>TGCATTTTTTTCACATCTGCACATTTGATGTTCCTACCACGCGCTA...</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4654389</td>\n",
       "      <td>TGCATTTTTTTCACATCGATAGTTGGTTGGATTTTACCGTTGATAG...</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2266084</td>\n",
       "      <td>TGCATTTTTTTCACATCTCTGTAGGGTTCATCACCTGTTTTATGGG...</td>\n",
       "      <td>8.490439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5141768</td>\n",
       "      <td>TGCATTTTTTTCACATCGCTGTGCCTTGCGCATGCTTGGGGTGTAT...</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5849166</td>\n",
       "      <td>TGCATTTTTTTCACATCAATGATTCGCCTAGCTCGATTGTTTATGC...</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673921</th>\n",
       "      <td>4269572</td>\n",
       "      <td>TGCATTTTTTTCACATCATTAATGTGGCCCCCGTATCCATATAGTT...</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673922</th>\n",
       "      <td>2416930</td>\n",
       "      <td>TGCATTTTTTTCACATCCGGAGACCGATTGTTGGATCCTAGAAGCA...</td>\n",
       "      <td>13.242847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673923</th>\n",
       "      <td>5680606</td>\n",
       "      <td>TGCATTTTTTTCACATCTAATTTGAAGTTTATTTGTCACATATTCT...</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673924</th>\n",
       "      <td>4536704</td>\n",
       "      <td>TGCATTTTTTTCACATCTTCCGGCGCGCATGATCGGTCTAATGTAA...</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673925</th>\n",
       "      <td>1299974</td>\n",
       "      <td>TGCATTTTTTTCACATCGCCATATCCGGGAAGAGGCCGCCTGTTTA...</td>\n",
       "      <td>12.933074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>673926 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          index                                                seq     target\n",
       "0       4105474  TGCATTTTTTTCACATCTGCACATTTGATGTTCCTACCACGCGCTA...  15.000000\n",
       "1       4654389  TGCATTTTTTTCACATCGATAGTTGGTTGGATTTTACCGTTGATAG...  11.000000\n",
       "2       2266084  TGCATTTTTTTCACATCTCTGTAGGGTTCATCACCTGTTTTATGGG...   8.490439\n",
       "3       5141768  TGCATTTTTTTCACATCGCTGTGCCTTGCGCATGCTTGGGGTGTAT...  13.000000\n",
       "4       5849166  TGCATTTTTTTCACATCAATGATTCGCCTAGCTCGATTGTTTATGC...   9.000000\n",
       "...         ...                                                ...        ...\n",
       "673921  4269572  TGCATTTTTTTCACATCATTAATGTGGCCCCCGTATCCATATAGTT...  12.000000\n",
       "673922  2416930  TGCATTTTTTTCACATCCGGAGACCGATTGTTGGATCCTAGAAGCA...  13.242847\n",
       "673923  5680606  TGCATTTTTTTCACATCTAATTTGAAGTTTATTTGTCACATATTCT...   8.000000\n",
       "673924  4536704  TGCATTTTTTTCACATCTTCCGGCGCGCATGATCGGTCTAATGTAA...  12.000000\n",
       "673925  1299974  TGCATTTTTTTCACATCGCCATATCCGGGAAGAGGCCGCCTGTTTA...  12.933074\n",
       "\n",
       "[673926 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tfrecord\n",
    "\n",
    "def get_data_TFRecord_worker(dataset, outprefix):\n",
    "\n",
    "    TFRecord_file = outprefix + \".TFRecord\"\n",
    "    writer = tfrecord.TFRecordWriter(TFRecord_file)\n",
    "    count = 0\n",
    "    for idx, (seq, target) in enumerate(dataset):\n",
    "        writer.write({'seq': (list(seq.flatten()), 'float'),\n",
    "                        'target': (target[0], 'float')})\n",
    "        count += 1\n",
    "        if count % 100000 == 0: print(f\"{count} written\")\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_data_TFRecord_worker(dataset_train, \"train\")\n",
    "#get_data_TFRecord_worker(dataset_val, \"val\")\n",
    "#get_data_TFRecord_worker(dataset_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### webdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webdataset as wds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = DreamChallengeDataset(df_train.reset_index(), transform=DNA2OneHot())\n",
    "dataset_val = DreamChallengeDataset(df_val.reset_index(), transform=DNA2OneHot())\n",
    "dataset_test = DreamChallengeDataset(df_test.reset_index(), transform=DNA2OneHot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeWDS(dataset, prefix):\n",
    "    sink = wds.ShardWriter(\"./shards/\" + prefix + \"-%02d.tar\", maxcount=10000)\n",
    "    count = 0\n",
    "    for idx, (seq, target) in enumerate(dataset):\n",
    "        sink.write({\n",
    "            '__key__': 'sample%06d' % idx,\n",
    "            'seq.npy': seq,\n",
    "            'target.npy': target\n",
    "        })\n",
    "        count += 1\n",
    "        if count % 100000 == 0: print(f\"{count} written\")\n",
    "    sink.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeWDS(dataset_train, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeWDS(dataset_val, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeWDS(dataset_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.read_table(\"./data/test_sequences.txt\", header=None, names=['seq', 'target'], dtype={'seq':str, 'target':np.float32})\n",
    "dataset_predict = DreamChallengeDataset(df_predict, transform=DNA2OneHot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeWDS(dataset_predict, \"pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataloader.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataloader.py\n",
    "\n",
    "# lightning data module\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities import cli as pl_cli\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "import webdataset as wds\n",
    "\n",
    "class DNA2OneHot(object):\n",
    "    def __init__(self, expect_len=110, rev=False):\n",
    "        self.expect_len = expect_len\n",
    "        self.rev = rev\n",
    "        self.DNA2Index = {\n",
    "            \"A\": 0,\n",
    "            \"C\": 1,\n",
    "            \"G\": 2,\n",
    "            \"T\": 3\n",
    "        }\n",
    "    \n",
    "    def __call__(self, dnaSeq):\n",
    "        # initialize the matrix as 4 x self.expect_len\n",
    "        seqMatrixs = np.zeros((4, self.expect_len), dtype=np.float32)\n",
    "        # change the value to matrix\n",
    "        seqLen = len(dnaSeq)\n",
    "        dnaSeq = self.rev_comp(dnaSeq.upper()) if self.rev else dnaSeq.upper()\n",
    "        for j in range(0, min(seqLen, self.expect_len)):\n",
    "            try:\n",
    "                seqMatrixs[self.DNA2Index[dnaSeq[j]], j] = 1\n",
    "            except KeyError as e:\n",
    "                continue\n",
    "        return seqMatrixs\n",
    "\n",
    "class DreamChallengeDataset(Dataset):\n",
    "    def __init__(self, df=None, transform=None, target_transform=None):\n",
    "        self.seq = df.seq\n",
    "        self.target = df.target\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq.iloc[idx]\n",
    "        target = self.target.iloc[idx][np.newaxis]\n",
    "        if self.transform:\n",
    "            seq = self.transform(seq)\n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "        return seq, target\n",
    "\n",
    "    def rev_comp(self, inp_str):\n",
    "        rc_dict = {'A': 'T', 'G': 'C', 'T': 'A', 'C': 'G', 'c': 'g',\n",
    "                   'g': 'c', 't': 'a', 'a': 't', 'n': 'n', 'N': 'N'}\n",
    "        outp_str = list()\n",
    "        for nucl in inp_str:\n",
    "            outp_str.append(rc_dict[nucl])\n",
    "        return ''.join(outp_str)[::-1]    \n",
    "\n",
    "def npy_decoder(key, value):\n",
    "    if not key.endswith(\".npy\"):\n",
    "        return None\n",
    "    assert isinstance(value, bytes)\n",
    "    return np.load(io.BytesIO(value))\n",
    "\n",
    "def worker_splitter(urls):\n",
    "    urls = [url for url in urls]\n",
    "    assert isinstance(urls, list)\n",
    "\n",
    "    worker_info = torch.utils.data.get_worker_info()\n",
    "    if worker_info is not None:\n",
    "        wid = worker_info.id\n",
    "        num_workers = worker_info.num_workers\n",
    "\n",
    "        return iter(urls[wid::num_workers])\n",
    "    else:\n",
    "        return iter(urls)\n",
    "\n",
    "def node_splitter(urls):\n",
    "    urls = [url for url in urls]\n",
    "\n",
    "    shard_id = torch.distributed.get_rank()\n",
    "    num_shards = torch.distributed.get_world_size()\n",
    "\n",
    "    urls_this = urls[shard_id::num_shards]\n",
    "\n",
    "    return iter(urls_this)\n",
    "\n",
    "@pl_cli.DATAMODULE_REGISTRY\n",
    "class DreamChallengeDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str=\"./shards/\", train_epochs=1, batch_size=512, num_workers=6):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = DNA2OneHot()\n",
    "        self.train_epochs = train_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.description = {\"seq\": \"float\", \"target\": \"float\"}\n",
    "\n",
    "        self.dataset_train = None\n",
    "        self.dataset_val = None\n",
    "        self.dataset_test = None\n",
    "        self.dataset_predict = None\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        # Assume data already in self.data_dir\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            shard_id = torch.distributed.get_rank()\n",
    "            num_shards = torch.distributed.get_world_size()\n",
    "            print(f\"shard id: {shard_id}, num shards: {num_shards}\")\n",
    "\n",
    "            self.dataset_train = wds.DataPipeline(\n",
    "                wds.ResampledShards(\"shards/train-{00..539}.tar\"),\n",
    "                wds.tarfile_to_samples(),\n",
    "                wds.shuffle(1000),\n",
    "                wds.decode(npy_decoder),\n",
    "                wds.shuffle(1000),\n",
    "                wds.to_tuple(\"seq.npy\", \"target.npy\"),\n",
    "                wds.batched(self.batch_size, partial=False)\n",
    "                ).with_epoch(5391406//self.batch_size//num_shards//self.num_workers)\n",
    "\n",
    "            self.dataset_val = wds.DataPipeline(\n",
    "                wds.SimpleShardList(\"shards/val-{00..67}.tar\"),\n",
    "                node_splitter,\n",
    "                worker_splitter,\n",
    "                wds.tarfile_to_samples(),\n",
    "                wds.decode(npy_decoder),\n",
    "                wds.to_tuple(\"seq.npy\", \"target.npy\"),\n",
    "                wds.batched(self.batch_size, partial=False)\n",
    "                )\n",
    "            #.with_length(673926//num_data_instances)\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.dataset_test = wds.DataPipeline(\n",
    "                wds.SimpleShardList(\"shards/test-{00..67}.tar\"),\n",
    "                worker_splitter,\n",
    "                wds.tarfile_to_samples(),\n",
    "                wds.decode(npy_decoder),\n",
    "                wds.to_tuple(\"seq.npy\", \"target.npy\"),\n",
    "                wds.batched(self.batch_size, partial=True)\n",
    "                )\n",
    "            #.with_length(673926)\n",
    "\n",
    "        if stage == \"predict\" or stage is None:\n",
    "            self.dataset_predict = wds.DataPipeline(\n",
    "                wds.SimpleShardList(\"shards/pred-{00..07}.tar\"),\n",
    "                worker_splitter,\n",
    "                wds.tarfile_to_samples(),\n",
    "                wds.decode(npy_decoder),\n",
    "                wds.to_tuple(\"seq.npy\", \"target.npy\"),\n",
    "                wds.batched(self.batch_size, partial=True)\n",
    "            )\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset_train, batch_size=1, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.dataset_val, batch_size=1, num_workers=self.num_workers)\n",
    "        \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.dataset_test, batch_size=1, num_workers=1)\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.dataset_predict, batch_size=1,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webdataset as wds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = wds.DataPipeline(\n",
    "    wds.SimpleShardList(\"shards/train-{00..539}.tar\"),\n",
    "    wds.tarfile_to_samples(),\n",
    "    wds.decode(npy_decoder),\n",
    "    wds.to_tuple(\"seq.npy\", \"target.npy\"),\n",
    "    wds.batched(512, partial=False)\n",
    ").with_epoch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 1., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 1., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 1., 1.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 1., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 1., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 1., 1.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 1., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 1., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 1., 1.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 1., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 1., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 1., 1.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 1., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 1., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 1., 1.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 1., ..., 0., 0., 0.],\n",
      "        [0., 1., 0., ..., 1., 0., 0.],\n",
      "        [1., 0., 0., ..., 0., 1., 1.]]], dtype=float32), array([[12.270287 ],\n",
      "       [14.919623 ],\n",
      "       [ 8.       ],\n",
      "       [14.       ],\n",
      "       [11.135542 ],\n",
      "       [15.       ],\n",
      "       [ 9.       ],\n",
      "       [13.414012 ],\n",
      "       [11.77508  ],\n",
      "       [12.       ],\n",
      "       [ 8.89142  ],\n",
      "       [13.       ],\n",
      "       [ 9.649432 ],\n",
      "       [12.       ],\n",
      "       [12.       ],\n",
      "       [14.       ],\n",
      "       [15.       ],\n",
      "       [ 8.464342 ],\n",
      "       [16.       ],\n",
      "       [10.425069 ],\n",
      "       [10.775293 ],\n",
      "       [ 9.55657  ],\n",
      "       [ 6.2227187],\n",
      "       [ 8.375604 ],\n",
      "       [14.135064 ],\n",
      "       [11.       ],\n",
      "       [12.       ],\n",
      "       [10.       ],\n",
      "       [12.       ],\n",
      "       [10.       ],\n",
      "       [15.       ],\n",
      "       [11.146976 ],\n",
      "       [11.       ],\n",
      "       [11.       ],\n",
      "       [12.       ],\n",
      "       [11.747961 ],\n",
      "       [ 7.       ],\n",
      "       [10.       ],\n",
      "       [10.       ],\n",
      "       [ 9.437589 ],\n",
      "       [10.       ],\n",
      "       [15.       ],\n",
      "       [12.       ],\n",
      "       [12.       ],\n",
      "       [ 3.433108 ],\n",
      "       [16.       ],\n",
      "       [10.184998 ],\n",
      "       [11.       ],\n",
      "       [12.       ],\n",
      "       [13.       ],\n",
      "       [11.       ],\n",
      "       [13.758564 ],\n",
      "       [ 9.862306 ],\n",
      "       [13.       ],\n",
      "       [ 6.552605 ],\n",
      "       [11.       ],\n",
      "       [ 9.141672 ],\n",
      "       [16.       ],\n",
      "       [16.       ],\n",
      "       [15.       ],\n",
      "       [11.       ],\n",
      "       [11.126585 ],\n",
      "       [11.       ],\n",
      "       [ 9.       ],\n",
      "       [14.251629 ],\n",
      "       [16.88354  ],\n",
      "       [12.       ],\n",
      "       [13.       ],\n",
      "       [11.       ],\n",
      "       [ 9.       ],\n",
      "       [11.       ],\n",
      "       [ 8.       ],\n",
      "       [15.       ],\n",
      "       [ 9.842532 ],\n",
      "       [ 9.509753 ],\n",
      "       [15.       ],\n",
      "       [12.       ],\n",
      "       [12.       ],\n",
      "       [10.868469 ],\n",
      "       [12.       ],\n",
      "       [ 7.3036866],\n",
      "       [13.       ],\n",
      "       [ 9.483618 ],\n",
      "       [15.       ],\n",
      "       [10.847264 ],\n",
      "       [ 7.3325424],\n",
      "       [14.       ],\n",
      "       [11.       ],\n",
      "       [ 7.0459185],\n",
      "       [15.       ],\n",
      "       [11.       ],\n",
      "       [11.660388 ],\n",
      "       [10.       ],\n",
      "       [ 6.6451654],\n",
      "       [10.19656  ],\n",
      "       [11.       ],\n",
      "       [ 9.205845 ],\n",
      "       [11.       ],\n",
      "       [13.       ],\n",
      "       [12.310027 ],\n",
      "       [14.554664 ],\n",
      "       [11.927932 ],\n",
      "       [11.       ],\n",
      "       [14.700808 ],\n",
      "       [10.40774  ],\n",
      "       [11.       ],\n",
      "       [11.       ],\n",
      "       [ 9.       ],\n",
      "       [13.       ],\n",
      "       [14.       ],\n",
      "       [10.       ],\n",
      "       [11.94283  ],\n",
      "       [12.939216 ],\n",
      "       [13.271824 ],\n",
      "       [11.       ],\n",
      "       [10.696984 ],\n",
      "       [13.       ],\n",
      "       [10.079407 ],\n",
      "       [13.539746 ],\n",
      "       [10.463105 ],\n",
      "       [14.       ],\n",
      "       [10.159027 ],\n",
      "       [10.       ],\n",
      "       [12.       ],\n",
      "       [11.787042 ],\n",
      "       [11.       ],\n",
      "       [10.       ],\n",
      "       [12.       ],\n",
      "       [ 8.613191 ],\n",
      "       [10.       ],\n",
      "       [15.       ],\n",
      "       [ 6.759568 ],\n",
      "       [10.416747 ],\n",
      "       [16.       ],\n",
      "       [ 9.313382 ],\n",
      "       [10.       ],\n",
      "       [ 9.       ],\n",
      "       [ 9.       ],\n",
      "       [10.       ],\n",
      "       [ 9.248645 ],\n",
      "       [11.012881 ],\n",
      "       [14.365517 ],\n",
      "       [ 8.       ],\n",
      "       [13.       ],\n",
      "       [14.       ],\n",
      "       [12.141371 ],\n",
      "       [10.       ],\n",
      "       [12.844926 ],\n",
      "       [12.       ],\n",
      "       [ 8.375604 ],\n",
      "       [10.       ],\n",
      "       [10.       ],\n",
      "       [11.       ],\n",
      "       [ 7.329018 ],\n",
      "       [ 9.850053 ],\n",
      "       [15.       ],\n",
      "       [10.       ],\n",
      "       [ 8.       ],\n",
      "       [ 9.       ],\n",
      "       [11.       ],\n",
      "       [13.       ],\n",
      "       [10.589761 ],\n",
      "       [13.       ],\n",
      "       [11.       ],\n",
      "       [ 9.       ],\n",
      "       [12.673216 ],\n",
      "       [14.       ],\n",
      "       [12.       ],\n",
      "       [ 9.       ],\n",
      "       [13.       ],\n",
      "       [10.993867 ],\n",
      "       [11.       ],\n",
      "       [15.       ],\n",
      "       [10.223313 ],\n",
      "       [14.       ],\n",
      "       [11.       ],\n",
      "       [12.       ],\n",
      "       [ 9.       ],\n",
      "       [12.       ],\n",
      "       [ 6.       ],\n",
      "       [15.       ],\n",
      "       [ 9.       ],\n",
      "       [ 8.673464 ],\n",
      "       [12.       ],\n",
      "       [13.157848 ],\n",
      "       [ 9.       ],\n",
      "       [14.776665 ],\n",
      "       [ 9.040945 ],\n",
      "       [13.       ],\n",
      "       [ 7.       ],\n",
      "       [11.       ],\n",
      "       [12.327338 ],\n",
      "       [15.576355 ],\n",
      "       [ 3.056649 ],\n",
      "       [13.       ],\n",
      "       [ 9.       ],\n",
      "       [14.       ],\n",
      "       [13.       ],\n",
      "       [11.438356 ],\n",
      "       [12.       ],\n",
      "       [ 9.       ],\n",
      "       [12.       ],\n",
      "       [10.       ],\n",
      "       [14.       ],\n",
      "       [ 7.5270762],\n",
      "       [11.273286 ],\n",
      "       [14.431273 ],\n",
      "       [10.       ],\n",
      "       [14.466214 ],\n",
      "       [13.       ],\n",
      "       [11.829696 ],\n",
      "       [12.738906 ],\n",
      "       [ 9.978939 ],\n",
      "       [ 6.2250013],\n",
      "       [ 9.       ],\n",
      "       [14.75388  ],\n",
      "       [12.948695 ],\n",
      "       [ 9.       ],\n",
      "       [11.       ],\n",
      "       [12.       ],\n",
      "       [11.838016 ],\n",
      "       [10.463968 ],\n",
      "       [16.       ],\n",
      "       [13.       ],\n",
      "       [11.       ],\n",
      "       [10.       ],\n",
      "       [11.       ],\n",
      "       [10.       ],\n",
      "       [11.       ],\n",
      "       [14.868039 ],\n",
      "       [11.489191 ],\n",
      "       [11.       ],\n",
      "       [10.012526 ],\n",
      "       [11.634649 ],\n",
      "       [13.491133 ],\n",
      "       [11.       ],\n",
      "       [10.105923 ],\n",
      "       [ 8.       ],\n",
      "       [12.       ],\n",
      "       [16.892355 ],\n",
      "       [11.794219 ],\n",
      "       [11.799895 ],\n",
      "       [11.553756 ],\n",
      "       [11.       ],\n",
      "       [12.       ],\n",
      "       [14.883891 ],\n",
      "       [13.106638 ],\n",
      "       [11.       ],\n",
      "       [ 5.779997 ],\n",
      "       [10.352536 ],\n",
      "       [14.       ],\n",
      "       [ 9.125939 ],\n",
      "       [ 8.       ],\n",
      "       [13.97832  ],\n",
      "       [15.       ],\n",
      "       [14.       ],\n",
      "       [14.9065695],\n",
      "       [11.759351 ],\n",
      "       [10.       ],\n",
      "       [15.       ],\n",
      "       [ 9.       ],\n",
      "       [ 8.       ],\n",
      "       [ 5.962623 ],\n",
      "       [13.       ],\n",
      "       [13.       ],\n",
      "       [12.       ],\n",
      "       [12.774209 ],\n",
      "       [ 8.896645 ],\n",
      "       [11.       ],\n",
      "       [12.       ],\n",
      "       [13.       ],\n",
      "       [12.       ],\n",
      "       [14.345863 ],\n",
      "       [10.237358 ],\n",
      "       [12.       ],\n",
      "       [12.       ],\n",
      "       [15.472188 ],\n",
      "       [10.177388 ],\n",
      "       [13.       ],\n",
      "       [10.       ],\n",
      "       [10.885884 ],\n",
      "       [ 9.463666 ],\n",
      "       [15.       ],\n",
      "       [15.       ],\n",
      "       [11.311896 ],\n",
      "       [11.       ],\n",
      "       [13.589989 ],\n",
      "       [11.       ],\n",
      "       [10.525844 ],\n",
      "       [12.       ],\n",
      "       [13.       ],\n",
      "       [11.635378 ],\n",
      "       [13.       ],\n",
      "       [12.070891 ],\n",
      "       [13.       ],\n",
      "       [11.       ],\n",
      "       [14.207811 ],\n",
      "       [15.       ],\n",
      "       [ 7.       ],\n",
      "       [14.700808 ],\n",
      "       [13.600915 ],\n",
      "       [14.       ],\n",
      "       [14.       ],\n",
      "       [15.       ],\n",
      "       [10.35027  ],\n",
      "       [13.19868  ],\n",
      "       [11.829356 ],\n",
      "       [13.392143 ],\n",
      "       [10.721269 ],\n",
      "       [14.       ],\n",
      "       [ 8.121069 ],\n",
      "       [14.322027 ],\n",
      "       [13.       ],\n",
      "       [ 7.49137  ],\n",
      "       [12.       ],\n",
      "       [ 9.602052 ],\n",
      "       [14.       ],\n",
      "       [13.       ],\n",
      "       [ 9.       ],\n",
      "       [14.       ],\n",
      "       [10.       ],\n",
      "       [10.497371 ],\n",
      "       [ 8.1904125],\n",
      "       [11.       ],\n",
      "       [ 8.       ],\n",
      "       [ 9.754202 ],\n",
      "       [15.       ],\n",
      "       [15.       ],\n",
      "       [10.561126 ],\n",
      "       [11.064477 ],\n",
      "       [ 9.       ],\n",
      "       [12.       ],\n",
      "       [15.       ],\n",
      "       [10.651432 ],\n",
      "       [13.077485 ],\n",
      "       [10.       ],\n",
      "       [11.       ],\n",
      "       [14.       ],\n",
      "       [12.       ],\n",
      "       [10.507397 ],\n",
      "       [ 9.       ],\n",
      "       [11.       ],\n",
      "       [13.       ],\n",
      "       [12.       ],\n",
      "       [14.438447 ],\n",
      "       [15.       ],\n",
      "       [11.       ],\n",
      "       [ 8.       ],\n",
      "       [12.563329 ],\n",
      "       [10.463105 ],\n",
      "       [11.       ],\n",
      "       [ 8.609147 ],\n",
      "       [ 8.643449 ],\n",
      "       [13.       ],\n",
      "       [12.       ],\n",
      "       [11.       ],\n",
      "       [13.       ],\n",
      "       [11.       ],\n",
      "       [11.       ],\n",
      "       [13.292525 ],\n",
      "       [14.638329 ],\n",
      "       [11.       ],\n",
      "       [10.730457 ],\n",
      "       [13.       ],\n",
      "       [11.231801 ],\n",
      "       [11.       ],\n",
      "       [10.       ],\n",
      "       [13.       ],\n",
      "       [10.857913 ],\n",
      "       [10.219077 ],\n",
      "       [ 9.200631 ],\n",
      "       [11.826102 ],\n",
      "       [14.       ],\n",
      "       [12.648535 ],\n",
      "       [13.       ],\n",
      "       [ 9.032022 ],\n",
      "       [12.882172 ],\n",
      "       [11.       ],\n",
      "       [ 3.       ],\n",
      "       [ 9.256463 ],\n",
      "       [13.       ],\n",
      "       [13.400464 ],\n",
      "       [ 8.304342 ],\n",
      "       [11.514261 ],\n",
      "       [ 5.502232 ],\n",
      "       [14.       ],\n",
      "       [12.61056  ],\n",
      "       [14.       ],\n",
      "       [11.992271 ],\n",
      "       [10.463105 ],\n",
      "       [ 8.230643 ],\n",
      "       [10.441553 ],\n",
      "       [13.       ],\n",
      "       [12.678134 ],\n",
      "       [10.       ],\n",
      "       [13.       ],\n",
      "       [10.5475025],\n",
      "       [11.       ],\n",
      "       [16.742426 ],\n",
      "       [13.       ],\n",
      "       [10.32511  ],\n",
      "       [12.11874  ],\n",
      "       [ 2.068764 ],\n",
      "       [14.104993 ],\n",
      "       [10.75118  ],\n",
      "       [11.       ],\n",
      "       [ 5.0497828],\n",
      "       [ 5.689861 ],\n",
      "       [ 9.759552 ],\n",
      "       [14.       ],\n",
      "       [ 9.       ],\n",
      "       [ 8.       ],\n",
      "       [ 8.       ],\n",
      "       [10.       ],\n",
      "       [14.       ],\n",
      "       [13.       ],\n",
      "       [14.700808 ],\n",
      "       [14.       ],\n",
      "       [15.       ],\n",
      "       [10.026241 ],\n",
      "       [10.       ],\n",
      "       [10.703444 ],\n",
      "       [13.       ],\n",
      "       [ 5.599386 ],\n",
      "       [14.       ],\n",
      "       [ 9.832769 ],\n",
      "       [10.       ],\n",
      "       [10.168242 ],\n",
      "       [12.       ],\n",
      "       [ 8.209791 ],\n",
      "       [ 8.643449 ],\n",
      "       [14.       ],\n",
      "       [11.128682 ],\n",
      "       [14.       ],\n",
      "       [13.       ],\n",
      "       [ 7.8715196],\n",
      "       [10.       ],\n",
      "       [12.       ],\n",
      "       [12.       ],\n",
      "       [ 8.       ],\n",
      "       [10.938052 ],\n",
      "       [14.       ],\n",
      "       [ 9.206798 ],\n",
      "       [10.463105 ],\n",
      "       [12.278802 ],\n",
      "       [13.       ],\n",
      "       [11.       ],\n",
      "       [13.       ],\n",
      "       [ 6.2028136],\n",
      "       [15.       ],\n",
      "       [12.       ],\n",
      "       [14.       ],\n",
      "       [12.255336 ],\n",
      "       [14.787706 ],\n",
      "       [15.       ],\n",
      "       [ 4.       ],\n",
      "       [15.       ],\n",
      "       [11.       ],\n",
      "       [ 8.331279 ],\n",
      "       [11.973106 ],\n",
      "       [10.       ],\n",
      "       [14.875421 ],\n",
      "       [13.       ],\n",
      "       [15.       ],\n",
      "       [10.       ],\n",
      "       [13.391518 ],\n",
      "       [13.141715 ],\n",
      "       [11.       ],\n",
      "       [ 8.445081 ],\n",
      "       [ 7.115586 ],\n",
      "       [14.       ],\n",
      "       [10.931438 ],\n",
      "       [16.259954 ],\n",
      "       [ 9.694127 ],\n",
      "       [12.       ],\n",
      "       [10.536282 ],\n",
      "       [12.0201645],\n",
      "       [14.       ],\n",
      "       [14.       ],\n",
      "       [15.       ],\n",
      "       [14.       ],\n",
      "       [10.       ],\n",
      "       [12.       ],\n",
      "       [ 8.375604 ],\n",
      "       [15.       ],\n",
      "       [12.843945 ],\n",
      "       [10.       ],\n",
      "       [12.       ],\n",
      "       [13.       ],\n",
      "       [13.       ],\n",
      "       [14.       ],\n",
      "       [12.443646 ],\n",
      "       [13.       ],\n",
      "       [11.       ],\n",
      "       [13.       ],\n",
      "       [14.       ],\n",
      "       [14.       ],\n",
      "       [15.       ],\n",
      "       [14.985492 ],\n",
      "       [ 8.507754 ],\n",
      "       [12.       ],\n",
      "       [ 9.       ],\n",
      "       [10.       ],\n",
      "       [13.       ],\n",
      "       [ 9.       ],\n",
      "       [11.       ],\n",
      "       [ 9.672772 ],\n",
      "       [12.       ],\n",
      "       [10.095092 ],\n",
      "       [ 7.332988 ],\n",
      "       [14.       ],\n",
      "       [10.616324 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for i in ds: print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DreamChallengeDataModule(transform=DNA2OneHot())\n",
    "ds.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train\n",
    "ds_train = ds.train_dataloader()\n",
    "targets = []\n",
    "for seq, target in ds_train:\n",
    "    targets.append(target)\n",
    "targets = torch.cat(targets)\n",
    "# plot histogram on targets\n",
    "targets.numpy()\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = sns.histplot(x=targets, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ8AAAI/CAYAAADZQXilAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAk+klEQVR4nO3df5Dtd13f8dc790JAEAxwobB3r4klYwVm/EEMGFqGGpVIHYMOmOuoZGzaxBSpaGsFnalOZzIDrYriFEwKlEAp3BihxBZUGtBOGwxckIohUG4Fcjc3TaJQwFojN3z6x36v3Sy7d8/e7Ht/Ph4zO3v2c77fk8/ZfOfs3ud+vt9TY4wAAAAAQIeztnoCAAAAAOxe4hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBm/1ZPYLM97nGPG+eee+5WTwMAAABg1/jQhz70p2OMAyvdt+fi07nnnpujR49u9TQAAAAAdo2q+sxq9zntDgAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAdpG5+UOpqjU/5uYPbfVUAdgj9m/1BAAAgI1zYuF4Lrv2ljW3O3LVRZswGwCw8gkAAACARuITAAAAAG3EJwAAAADaiE8AAAAAtBGfAAAAAGgjPgEAAADQRnwCAAAAoI34BAAAAEAb8QkAAACANuITAAAAAG3EJwAAAADaiE8AAAAAtBGfAAAAAGgjPgEAAADQRnwCAAAAoI34BAAAAEAb8QkAAACANuITAAAAAG3EJwAAAADaiE8AAAAAtBGfAAAAAGgjPgEAAADQRnwCAAAAoI34BAAAAEAb8QkAAACANuITAAAAAG3EJwAAAADaiE8AAAAAtBGfAAAAAGgjPgEAAADQRnwCAAAAoI34BAAAAEAb8QkAAACANuITAAAAAG3EJwAAAADaiE8AAAAAtBGfAAAAAGgjPgEAAADQRnwCAAAAoI34BAAAAEAb8QkAAACANuITAAAAAG3EJwAAAADaiE8AAAAAtBGfAAAAAGgjPgEAAADQRnwCAAAAoI34BAAAAEAb8QkAAACANuITAAAAAG3EJwAAAADaiE8AAAAAtBGfAAAAAGgjPgEAAADQRnwCAAAAoI34BAAAAEAb8QkAAACANq3xqap+sqpuq6o/rqq3VtXDquoxVfWeqvrk9PmcJdu/vKqOVdUnquq5S8afXlUfne57dVXVNH52VR2Zxm+tqnM7nw8AAAAA69MWn6pqLsk/TnLBGONpSfYlOZzkZUluHmOcn+Tm6etU1VOm+5+a5JIkr6mqfdPDvTbJlUnOnz4umcavSPK5McaTk7wqySu7ng8AAAAA69d92t3+JA+vqv1JvirJiSSXJrl+uv/6JM+fbl+a5G1jjPvGGJ9KcizJhVX1xCSPGmO8f4wxkrxp2T6nHuvGJBefWhUFAAAAwNZri09jjDuT/GKSO5LcleTzY4zfTfKEMcZd0zZ3JXn8tMtckuNLHmJhGpubbi8ff8A+Y4yTST6f5LEdzwcAAACA9es87e6cLK5MOi/Jk5I8oqp++HS7rDA2TjN+un2Wz+XKqjpaVUfvvffe008cAAAAgA3TedrddyT51Bjj3jHGl5K8PclFSe6eTqXL9PmeafuFJPNL9j+YxdP0Fqbby8cfsM90at+jk3x2+UTGGNeNMS4YY1xw4MCBDXp6AAAAAKylMz7dkeSZVfVV03WYLk5ye5Kbklw+bXN5kndOt29Kcnh6B7vzsnhh8Q9Mp+Z9saqeOT3Oi5btc+qxXpDkvdN1oQAAAADYBvZ3PfAY49aqujHJh5OcTPKHSa5L8sgkN1TVFVkMVC+ctr+tqm5I8rFp+xePMe6fHu7qJG9M8vAk754+kuT1Sd5cVceyuOLpcNfzAQAAAGD92uJTkowxfj7Jzy8bvi+Lq6BW2v6aJNesMH40ydNWGP/LTPEKAAAAgO2n87Q7AAAAAPY48QkAAACANuITAAAAAG3EJwAAAADaiE8AAAAAtBGfAAAAAGgjPgEAAADQRnwCAAAAoI34BAAAAEAb8QkAAACANuITAAAAAG3EJwAAAADaiE8AAAAAtBGfAAAAAGgjPgEAAADQRnwCAAAAoI34BAAAAEAb8QkAAACANuITAAAAAG3EJwAAAADaiE8AAAAAtBGfAAAAAGgjPgEAAADQRnwCAAAAoI34BAAAAEAb8QkAAACANuITAAAAAG3EJwAAAADaiE8AAAAAtBGfAAAAAGgjPgEAAADQRnwCAAAAoI34BAAAAEAb8QkAAACANuITAAAAAG3EJwAAAADaiE8AAAAAtBGfAAAAAGgjPgEAAADQRnwCAAAAoI34BAAAAEAb8QkAAACANuITAAAAAG3EJwAAAADaiE8AAAAAtBGfAAAAAGgjPgEAAADQRnwCAAAAoI34BAAAAEAb8QkAAACANuITAACwo83NH0pVrfkxN39oq6cKsCft3+oJAAAAPBgnFo7nsmtvWXO7I1ddtAmzAWA5K58AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA2rfGpqr6mqm6sqo9X1e1V9W1V9Ziqek9VfXL6fM6S7V9eVceq6hNV9dwl40+vqo9O9726qmoaP7uqjkzjt1bVuZ3PBwAAAID16V759KtJfnuM8beSfGOS25O8LMnNY4zzk9w8fZ2qekqSw0memuSSJK+pqn3T47w2yZVJzp8+LpnGr0jyuTHGk5O8Kskrm58PAAAAAOvQFp+q6lFJnp3k9UkyxvirMcb/TnJpkuunza5P8vzp9qVJ3jbGuG+M8akkx5JcWFVPTPKoMcb7xxgjyZuW7XPqsW5McvGpVVEAAAAAbL3OlU9fl+TeJP+2qv6wql5XVY9I8oQxxl1JMn1+/LT9XJLjS/ZfmMbmptvLxx+wzxjjZJLPJ3lsz9MBAAAAYL0649P+JN+S5LVjjG9O8n8ynWK3ipVWLI3TjJ9unwc+cNWVVXW0qo7ee++9p581AAAAABumMz4tJFkYY9w6fX1jFmPU3dOpdJk+37Nk+/kl+x9McmIaP7jC+AP2qar9SR6d5LPLJzLGuG6MccEY44IDBw5swFMDAAAAYBZt8WmM8b+SHK+qr5+GLk7ysSQ3Jbl8Grs8yTun2zclOTy9g915Wbyw+AemU/O+WFXPnK7n9KJl+5x6rBckee90XSgAAAAAtoH9zY//kiRvqaqHJvmTJD+axeB1Q1VdkeSOJC9MkjHGbVV1QxYD1ckkLx5j3D89ztVJ3pjk4UnePX0kixczf3NVHcviiqfDzc8HAAAAgHVojU9jjI8kuWCFuy5eZftrklyzwvjRJE9bYfwvM8UrAAAAALafzms+AQAAALDHiU8AAAAAtBGfAAAAAGgjPgEAAADQRnwCAAAAoI34BAAAAEAb8QkAAACANuITAAAAAG3EJwAAAADaiE8AAAAAtBGfAAAAAGgjPgEAAADQRnwCAGDXmps/lKpa82Nu/tBWTxUAdq39Wz0BAADocmLheC679pY1tzty1UWbMBsA2JusfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAtr25+UOpqjU/5uYPbfVUgWX2z7JRVT1rjPHf1hoDAACADicWjueya29Zc7sjV120CbMB1mPWlU+/NuMYAAAAAPy10658qqpvS3JRkgNV9VNL7npUkn2dEwMAAABg51vrtLuHJnnktN1XLxn/QpIXdE0KAAAAgN3htPFpjPH7SX6/qt44xvjMJs0JAAAAgF1ipguOJzm7qq5Lcu7SfcYY394xKQAAAAB2h1nj028k+fUkr0tyf990AAAAANhNZo1PJ8cYr22dCQAAAAC7zlkzbvdbVfWPquqJVfWYUx+tMwMAAABgx5t15dPl0+efXjI2knzdxk4HAAAAgN1kpvg0xjiveyIAAAAA7D4zxaeqetFK42OMN23sdAAAAFjL3PyhnFg4vuZ2Tzo4nzuP37EJMwJY3ayn3X3rktsPS3Jxkg8nEZ8AAAA22YmF47ns2lvW3O7IVRdtwmwATm/W0+5esvTrqnp0kje3zAgAAACAXWPWd7tb7i+SnL+REwEAAABg95n1mk+/lcV3t0uSfUm+IckNXZMCAAAAYHeY9ZpPv7jk9skknxljLDTMBwAAAIBdZKbT7sYYv5/k40m+Osk5Sf6qc1IAAAAA7A4zxaeq+oEkH0jywiQ/kOTWqnpB58QAAAAA2PlmPe3u55J86xjjniSpqgNJ/nOSG7smBgAAAMDON+u73Z11KjxN/mwd+wIAAACwR8268um3q+p3krx1+vqyJO/qmRIAAAAAu8Vp41NVPTnJE8YYP11V35/kbyepJO9P8pZNmB8AAAAAO9hap879SpIvJskY4+1jjJ8aY/xkFlc9/Urv1AAAAADY6daKT+eOMf5o+eAY42iSc1tmBAAAAMCusVZ8ethp7nv4Rk4EAAAAgN1nrfj0war6h8sHq+qKJB/qmRIAAAAAu8Va73b30iTvqKofyv+PTRckeWiS72ucFwAAAAC7wGnj0xjj7iQXVdXfTfK0afg/jTHe2z4zAAAAAHa8tVY+JUnGGO9L8r7muQAAAACwy6x1zScAAAAAOGPiEwAAAABtxCcAAAAA2ohPAAAAALQRnwAAAABoIz4BAAAA0EZ8AgAAAKCN+AQAAABAG/EJAAAAgDbiEwAAAABtxCcAAAAA2ohPAAAAALQRnwAAAABoIz4BAAAA0EZ8AgAAAKCN+AQAAABAG/EJAAAAgDbiEwAAAABtxCcAAAAA2ohPAAAAALQRnwAAAABoIz4BAAAA0EZ8AgAAAKCN+AQAAABAm/b4VFX7quoPq+o/Tl8/pqreU1WfnD6fs2Tbl1fVsar6RFU9d8n406vqo9N9r66qmsbPrqoj0/itVXVu9/MBAAAAYHabsfLpJ5LcvuTrlyW5eYxxfpKbp69TVU9JcjjJU5NckuQ1VbVv2ue1Sa5Mcv70cck0fkWSz40xnpzkVUle2ftUAAAAAFiP1vhUVQeT/L0kr1syfGmS66fb1yd5/pLxt40x7htjfCrJsSQXVtUTkzxqjPH+McZI8qZl+5x6rBuTXHxqVRQAAAAAW6975dOvJPlnSb68ZOwJY4y7kmT6/PhpfC7J8SXbLUxjc9Pt5eMP2GeMcTLJ55M8dkOfAQAAAABnrC0+VdX3JLlnjPGhWXdZYWycZvx0+yyfy5VVdbSqjt57770zTgcAAACAB6tz5dOzknxvVX06yduSfHtV/bskd0+n0mX6fM+0/UKS+SX7H0xyYho/uML4A/apqv1JHp3ks8snMsa4boxxwRjjggMHDmzMswMAAABgTW3xaYzx8jHGwTHGuVm8kPh7xxg/nOSmJJdPm12e5J3T7ZuSHJ7ewe68LF5Y/APTqXlfrKpnTtdzetGyfU491gum/8ZXrHwCAAAAYGvs34L/5iuS3FBVVyS5I8kLk2SMcVtV3ZDkY0lOJnnxGOP+aZ+rk7wxycOTvHv6SJLXJ3lzVR3L4oqnw5v1JAAAAABY26bEpzHG7yX5ven2nyW5eJXtrklyzQrjR5M8bYXxv8wUrwAAOL25+UM5sXB87Q2TPOngfO48fkfzjACAvWArVj4BALAFTiwcz2XX3jLTtkeuuqh5NgDAXtF5wXEAAAAA9jjxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAA29Dc/KFU1Zofc/OHtnqqcFr7t3oCAAAAwFc6sXA8l117y5rbHbnqok2YDZw5K58AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA24hMAAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQBgDXPzh1JVa37MzR/a6qkCAGw7+7d6AgAA292JheO57Npb1tzuyFUXbcJsAAB2FiufAAAAAGgjPgEAAADQRnwCAAAAoI34BAAAAEAb8QkAAACANuITAAAAAG3EJwAAAADatMWnqpqvqvdV1e1VdVtV/cQ0/piqek9VfXL6fM6SfV5eVceq6hNV9dwl40+vqo9O9726qmoaP7uqjkzjt1bVuV3PBwAAAID161z5dDLJPxljfEOSZyZ5cVU9JcnLktw8xjg/yc3T15nuO5zkqUkuSfKaqto3PdZrk1yZ5Pzp45Jp/IoknxtjPDnJq5K8svH5AAAAALBObfFpjHHXGOPD0+0vJrk9yVySS5NcP212fZLnT7cvTfK2McZ9Y4xPJTmW5MKqemKSR40x3j/GGEnetGyfU491Y5KLT62KAgAAAGDrbco1n6bT4b45ya1JnjDGuCtZDFRJHj9tNpfk+JLdFqaxuen28vEH7DPGOJnk80ke2/IkAAAAAFi39vhUVY9M8ptJXjrG+MLpNl1hbJxm/HT7LJ/DlVV1tKqO3nvvvWtNGQAAAIAN0hqfquohWQxPbxljvH0avns6lS7T53um8YUk80t2P5jkxDR+cIXxB+xTVfuTPDrJZ5fPY4xx3RjjgjHGBQcOHNiIpwYAAADADDrf7a6SvD7J7WOMX15y101JLp9uX57knUvGD0/vYHdeFi8s/oHp1LwvVtUzp8d80bJ9Tj3WC5K8d7ouFAAAAADbwP7Gx35Wkh9J8tGq+sg09rNJXpHkhqq6IskdSV6YJGOM26rqhiQfy+I75b14jHH/tN/VSd6Y5OFJ3j19JItx681VdSyLK54ONz4fAAAAANapLT6NMf5rVr4mU5JcvMo+1yS5ZoXxo0metsL4X2aKVwAAAABsP5vybncAAAAA7E3iEwAAAABtxCcAAAAA2ohPAAAAALQRnwAAAABoIz4BAAAA0EZ8AgAAAKCN+AQAAABAG/EJAAAAgDbiEwAAAABtxCcAAAAA2ohPAAAAALQRnwAAAABoIz4BAAAA0EZ8AgAAAKCN+AQAAABAG/EJAAAAgDbiEwAAAABtxCcAAAAA2ohPAAAAALQRnwAAAABoIz4BAAAA0EZ8AgAAAKCN+AQAAABAG/EJAAAAgDbiEwAAAABtxCcAAAAA2ohPAAAAALQRnwAAAABoIz4BAAAA0EZ8AgAAAKCN+AQAAABAG/EJAAAAgDbiEwAAAABtxCcAAAAA2ohPAAAAALQRnwAAAABoIz4BAAAA0EZ8AgAAAKCN+AQAAABAG/EJAAAAgDbiEwAAAABtxCcAAAAA2ohPAAAAALQRnwAAAABoIz4BAAAA0EZ8AgAAAKCN+AQAAABAG/EJAAAAgDbiEwAAnLU/VTXTx/6HPmym7ebmD231swKAbWH/Vk8AAAC23JdP5rJrb5lp0yNXXTTTtkeuuujBzgoAdgUrnwAAoMOMq6mskAJgt7PyCQAAOsy4msoKKQB2OyufAAAAAGgjPgEA0G5u/pBT0ABgj3LaHQAA7U4sHHcKGgDsUVY+AQCw48y6kgoA2HpWPgEAcMbm5g/lxMLxTf/v7qqVVNO74q3lSQfnc+fxOzZhQgCwscQnAADO2K6KQFvFu+IBsMs57Q4AAACANlY+AQCwfcx4Ctqe5HsDwA4lPgEAsH04BW11vjcA7FDiEwAAX8kqGwBgg4hPAAB8JatsAIAN4oLjAMC6zM0fSlWt+TE3f2irpwoAwDZg5RMAsC4nFo5bEQMAwMysfAIAAACgjfgEAABsS7Oe5gvA9ua0OwAAYFtymi/A7mDlEwAAALDlZl3t6I1Ndh4rnwAAAIAtN+tqx8SKx53GyicAAAAA2ohPAADb1KynHzj1AADYzpx2BwCwUc7aP9M7b+17yNm5/0v3zfSQM11s+epne8cvAGDbEp8AADbKl0/O/M5cG/oOXuv47wIAbDan3QEAAADQRnwCAAA21azXMwNgd3DaHQAAsKlmfTv1vXiq6Nz8oZxYOL7V0wDYUOITAADANiHMAbuR0+4AAIAN4XQ6AFZi5RMAALAhrNoBYCVWPgEAwF501v6ZVinNzR/a6pnuClaFrc73BnY/K58AAGAv+vLJ2VYpXf1s//DfAFaFrc73BnY/8QkAAFjdjJEqEQcAWJnT7gAAgL3BqYYAW8LKJwAAYG+Y9VRDK7hoNDd/KCcWjm/1NGBTiU8AAABLTSuk1rLvIWfn/i/dtwkTYjeZ9RpXiRDK7iE+AQAALLWOFVIiwsqs7gGWEp8AAACYyXqikjAHnCI+AQAAMJNZTxkTlIClxCcAAIDdyvWrgG1AfAKAB2HW0w+edHA+dx6/YxNmtI1s8D94Zt1uT36vAVazwdevsqJpda5zBasTnwDgQXD6wWk0/INnpu2ufvZM0UukAmAj+Z0AVic+AQC7yzqiFwAA/c7a6gkAAGyJ6bTAWT4A2Lvm5g/5WcG6zXrczM0f2uqpbgornwCAvWnGFVKJVVIAu9F6rtFkRS3r5TTMBxKfAAAA2HPEgc3jYuyITwAAAOweM77bKptH6EN8AgAAYPfwxhOw7bjgOABshhkvbr3/oQ9zcUoAAHYVK58A2DCzns//pIPzufP4HZswo21kHX+F9ddaAAB2E/EJgA3jfP5NNOP1LPY95Ozc/6X7ZnrIPRkFAQBoJz4BwE60wSupkuTI1c92gVYAYGbexY5ZiU8AbL4ZV+1YibPJXKAVAFgHq96ZlfgE0MT1j05j1sgx40ocp5YBAGwcK5rYaDs+PlXVJUl+Ncm+JK8bY7xii6cEkGQdfwmaMbDsyWiyhaeWrSdoAQBsqYZrQVrRxEba0fGpqvYl+ddJvjPJQpIPVtVNY4yPbe3MgOWsAjqNDV4FlOzR7+OsvOscALDb+P2GbW5Hx6ckFyY5Nsb4kySpqrcluTSJ+MS2tp5lrLP+dWK7x4aNXgWU7J7vzcxm/KUi2fjVPVYBAQCAUxLP1E6PT3NJlv5fX0jyjC2ay6bbTStJZn0uG/0P5a363swaYpJ1/HVig2PDrN+bDX/xXU9g2aLvzY4IMQ1//fJXMgAAto0NPtXQKYm9aoyx1XM4Y1X1wiTPHWP8g+nrH0ly4RjjJcu2uzLJldOXX5/kE5s60T6PS/KnWz0JdhXHFBvNMcVGc0zRwXHFRnNMsdEcU2y0jmPqa8cYB1a6Y6evfFpIMr/k64NJTizfaIxxXZLrNmtSm6Wqjo4xLtjqebB7OKbYaI4pNppjig6OKzaaY4qN5phio232MXXWZv2HmnwwyflVdV5VPTTJ4SQ3bfGcAAAAAJjs6JVPY4yTVfXjSX4nyb4kbxhj3LbF0wIAAABgsqPjU5KMMd6V5F1bPY8tsutOJWTLOabYaI4pNppjig6OKzaaY4qN5phio23qMbWjLzgOAAAAwPa206/5BAAAAMA2Jj5tc1V1SVV9oqqOVdXLVri/qurV0/1/VFXfshXzZOeoqvmqel9V3V5Vt1XVT6ywzXOq6vNV9ZHp459vxVzZOarq01X10el4ObrC/V6rmFlVff2S15+PVNUXquqly7bxOsWaquoNVXVPVf3xkrHHVNV7quqT0+dzVtn3tL+DsTetckz9q6r6+PTz7R1V9TWr7Hvan5XsTascU79QVXcu+Rn3vFX29TrFV1jlmDqy5Hj6dFV9ZJV9216nnHa3jVXVviT/I8l3JlnI4rv7/eAY42NLtnlekpckeV6SZyT51THGM7ZguuwQVfXEJE8cY3y4qr46yYeSPH/ZcfWcJP90jPE9WzNLdpqq+nSSC8YYf7rK/V6rOCPTz8I7kzxjjPGZJePPidcp1lBVz07y50neNMZ42jT2L5N8dozxiukfa+eMMX5m2X5r/g7G3rTKMfVdSd47vRnSK5Nk+TE1bffpnOZnJXvTKsfULyT58zHGL55mP69TrGilY2rZ/b+U5PNjjH+xwn2fTtPrlJVP29uFSY6NMf5kjPFXSd6W5NJl21yaxYNqjDH+IMnXTHEBVjTGuGuM8eHp9heT3J5kbmtnxR7gtYozdXGS/7k0PMGsxhj/Jclnlw1fmuT66fb1SZ6/wq6z/A7GHrTSMTXG+N0xxsnpyz9IcnDTJ8aOtcrr1Cy8TrGi0x1TVVVJfiDJWzd1UhGftru5JMeXfL2Qr4wEs2wDK6qqc5N8c5JbV7j726rqv1fVu6vqqZs7M3agkeR3q+pDVXXlCvd7reJMHc7qvyB5neJMPGGMcVey+AeZJI9fYRuvWZypv5/k3avct9bPSljqx6dTOd+wyunBXqc4E38nyd1jjE+ucn/b65T4tL3VCmPLz5OcZRv4ClX1yCS/meSlY4wvLLv7w0m+dozxjUl+Lcl/2OTpsfM8a4zxLUm+O8mLp+W+S3mtYt2q6qFJvjfJb6xwt9cpOnnNYt2q6ueSnEzyllU2WetnJZzy2iR/M8k3JbkryS+tsI3XKc7ED+b0q57aXqfEp+1tIcn8kq8PJjlxBtvAA1TVQ7IYnt4yxnj78vvHGF8YY/z5dPtdSR5SVY/b5Gmyg4wxTkyf70nyjiwuBV/KaxVn4ruTfHiMcffyO7xO8SDcfeq03+nzPSts4zWLdamqy5N8T5IfGqtcVHeGn5WQJBlj3D3GuH+M8eUk/yYrHytep1iXqtqf5PuTHFltm87XKfFpe/tgkvOr6rzpr7+Hk9y0bJubkrxo8Y2k6plZvHDYXZs9UXaO6Tzf1ye5fYzxy6ts8zem7VJVF2bxteLPNm+W7CRV9Yjp4vWpqkck+a4kf7xsM69VnIlV/zrndYoH4aYkl0+3L0/yzhW2meV3MEiy+I5jSX4myfeOMf5ilW1m+VkJSf46jJ/yfVn5WPE6xXp9R5KPjzEWVrqz+3Vq/0Y9EBtveseMH0/yO0n2JXnDGOO2qvqx6f5fT/KuLL571LEkf5HkR7dqvuwYz0ryI0k+uuQtNn82yaHkr4+rFyS5uqpOJvm/SQ6v9lc8SPKEJO+YOsD+JP9+jPHbXqt4MKrqq7L4Dj5XLRlbekx5nWJNVfXWJM9J8riqWkjy80lekeSGqroiyR1JXjht+6QkrxtjPG+138G24jmwvaxyTL08ydlJ3jP9LPyDMcaPLT2mssrPyi14CmwzqxxTz6mqb8riaXSfzvSz0OsUs1jpmBpjvD4rXEdzM1+nyu9pAAAAAHRx2h0AAAAAbcQnAAAAANqITwAAAAC0EZ8AAAAAaCM+AQAAANBGfAIAAACgjfgEAAAAQBvxCQAAAIA2/w/ShXbxCFLubQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# val\n",
    "ds_val = ds.val_dataloader()\n",
    "targets = []\n",
    "for seq, target in ds_val:\n",
    "    targets.append(target)\n",
    "targets = torch.cat(targets)\n",
    "# plot histogram on targets\n",
    "targets.numpy()\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = sns.histplot(x=targets, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test\n",
    "ds_test = ds.test_dataloader()\n",
    "targets = []\n",
    "for seq, target in ds_test:\n",
    "    targets.append(target)\n",
    "targets = torch.cat(targets)\n",
    "# plot histogram on targets\n",
    "targets.numpy()\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = sns.histplot(x=targets, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightning training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lightning_dreamchallenge.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lightning_dreamchallenge.py\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch import nn\n",
    "from pytorch_lightning.utilities.cli import LightningCLI\n",
    "from pytorch_lightning.utilities import cli as pl_cli\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from scipy.stats import pearsonr\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from dataloader import DreamChallengeDataModule\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.flatten(x, start_dim=1)\n",
    "\n",
    "class NNHooks(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        seq, y = batch\n",
    "        y_hat = self(seq)\n",
    "        y = torch.squeeze(y, 0)\n",
    "        #print(torch.stack([y, y_hat], 1)[:5])\n",
    "\n",
    "        # compute loss\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        seq, y = batch\n",
    "        y_hat = self(seq)\n",
    "        y = torch.squeeze(y, 0)\n",
    "        #print(torch.stack([y, y_hat], 1)[:5])\n",
    "\n",
    "        # compute loss\n",
    "        val_loss = F.mse_loss(y_hat, y)\n",
    "        self.log('val_loss', val_loss)\n",
    "        return {'val_loss': val_loss, 'pred': y_hat, 'true': y}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        seq, y = batch\n",
    "        y_hat = self(seq)\n",
    "        y = torch.squeeze(y, 0)\n",
    "\n",
    "        # compute loss\n",
    "        test_loss = F.mse_loss(y_hat, y)\n",
    "        self.log('test_loss', test_loss)\n",
    "        return {'test_loss': test_loss}\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        seq, y = batch\n",
    "        y_hat = self(seq)\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "    def validation_epoch_end(self, test_step_outputs):\n",
    "        # plot a scatterplot to show correlation between prediction and target\n",
    "        # collect outputs from each batch\n",
    "        out_preds = []\n",
    "        out_trues = []\n",
    "        out_labels = []\n",
    "        for outs in test_step_outputs:\n",
    "            out_preds.append(outs['pred'])\n",
    "            out_trues.append(outs['true'])\n",
    "        \n",
    "        # gather from ddp processes\n",
    "        out_preds = self.all_gather(torch.stack(out_preds))\n",
    "        out_trues = self.all_gather(torch.stack(out_trues))\n",
    "\n",
    "        # plot figure in the main process\n",
    "        if self.local_rank == 0: \n",
    "            out_preds = out_preds.detach().cpu().numpy().flatten()\n",
    "            out_trues = out_trues.detach().cpu().numpy().flatten()\n",
    "\n",
    "            fig = plt.figure(figsize=(12, 12))\n",
    "            ax = sns.scatterplot(x=out_preds, y=out_trues)\n",
    "            ax.set_xlim(left=0, right=8)\n",
    "            ax.text(0.1, 0.8, f\"pearsonr correlation efficient/p-value \\n{pearsonr(out_preds, out_trues)}\", transform=plt.gca().transAxes)\n",
    "            self.logger.experiment.add_figure(f\"Prediction vs True on validation dataset after epoch {self.current_epoch}\", fig)\n",
    "\n",
    "    def on_predict_epoch_end(self, predict_step_outputs):\n",
    "        # collect outputs from each batch\n",
    "        out_preds = []\n",
    "        for outs in predict_step_outputs[0]: \n",
    "            out_preds.append(outs)\n",
    "        \n",
    "        # gather from ddp processes\n",
    "        out_preds = self.all_gather(torch.cat(out_preds))\n",
    "\n",
    "        # save\n",
    "        if self.global_rank == 0:\n",
    "            np.savetxt(os.path.join(self.logger.log_dir, \"model_preds.txt\"), out_preds.cpu().numpy().flatten(), fmt=\"%.6f\")\n",
    "        print(f\"Saved model predictions into model_preds.txt\")\n",
    "\n",
    "@pl_cli.MODEL_REGISTRY\n",
    "class ConvolutionalModel(NNHooks):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.model_strand_specific_forward = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv1d(4, 256, 31, padding=15)),\n",
    "            ('relu1', nn.LeakyReLU()),\n",
    "            ('batchnorm1', nn.BatchNorm1d(256)),\n",
    "            ('conv2', nn.Conv1d(256, 256, 31, padding=15)),\n",
    "            ('relu2', nn.LeakyReLU()),\n",
    "            ('batchnorm2', nn.BatchNorm1d(256)),\n",
    "        ]))\n",
    "        self.model_strand_specific_reverse = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv1d(4, 256, 31, padding=15)),\n",
    "            ('relu1', nn.LeakyReLU()),\n",
    "            ('batchnorm1', nn.BatchNorm1d(256)),\n",
    "            ('conv2', nn.Conv1d(256, 256, 31, padding=15)),\n",
    "            ('relu2', nn.LeakyReLU()),\n",
    "            ('batchnorm1', nn.BatchNorm1d(256)),\n",
    "        ]))\n",
    "        self.model_body = nn.Sequential(OrderedDict([\n",
    "            ('conv3', nn.Conv1d(512, 256, 31, padding=15)),\n",
    "            ('relu3', nn.LeakyReLU()),\n",
    "            ('batchnorm3', nn.BatchNorm1d(256)),\n",
    "            ('conv4', nn.Conv1d(256, 256, 31, padding=15)),\n",
    "            ('relu4', nn.LeakyReLU()),\n",
    "            ('batchnorm4', nn.BatchNorm1d(256)),\n",
    "            ('faltten', Flatten()),\n",
    "            ('dense1', nn.Linear(110*256, 256)),\n",
    "            ('relu5', nn.LeakyReLU()),\n",
    "            ('batchnorm5', nn.BatchNorm1d(256)),\n",
    "            ('dropout1', nn.Dropout(self.dropout)),\n",
    "            ('dense2', nn.Linear(256, 256)),\n",
    "            ('relu6', nn.LeakyReLU()),\n",
    "            ('batchnorm6', nn.BatchNorm1d(256)),\n",
    "            ('dropout1', nn.Dropout(self.dropout))\n",
    "        ]))\n",
    "        self.model_head = nn.Sequential(OrderedDict([\n",
    "            ('dense_head', nn.Linear(256, 1))\n",
    "        ]))\n",
    "\n",
    "    def forward(self, seq):\n",
    "        seq = torch.squeeze(seq, 0)\n",
    "        seq_revcomp = torch.flip(seq.detach().clone(), [1, 2])\n",
    "        y_hat_for = self.model_strand_specific_forward(seq)\n",
    "        y_hat_rev = self.model_strand_specific_reverse(seq_revcomp)\n",
    "        y_hat = torch.cat([y_hat_for, y_hat_rev], dim=1)\n",
    "        y_hat = self.model_body(y_hat)\n",
    "        y_hat = self.model_head(y_hat)\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "@pl_cli.MODEL_REGISTRY\n",
    "class ConvolutionalModelAdj(NNHooks):\n",
    "    def __init__(self, dropout=0.5, num_conv=2, dilation=1):\n",
    "        super().__init__()\n",
    "        self.num_conv = num_conv\n",
    "        self.dilation = dilation\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.model_strand_specific_forward = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv1d(4, 256, 31, padding=15)),\n",
    "            ('relu1', nn.LeakyReLU()),\n",
    "            ('batchnorm1', nn.BatchNorm1d(256)),\n",
    "            ('conv2', nn.Conv1d(256, 256, 31, padding=15)),\n",
    "            ('relu2', nn.LeakyReLU()),\n",
    "            ('batchnorm2', nn.BatchNorm1d(256)),\n",
    "        ]))\n",
    "        self.model_strand_specific_reverse = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv1d(4, 256, 31, padding=15)),\n",
    "            ('relu1', nn.LeakyReLU()),\n",
    "            ('batchnorm1', nn.BatchNorm1d(256)),\n",
    "            ('conv2', nn.Conv1d(256, 256, 31, padding=15)),\n",
    "            ('relu2', nn.LeakyReLU()),\n",
    "            ('batchnorm1', nn.BatchNorm1d(256)),\n",
    "        ]))\n",
    "        conv_repeat_dict = OrderedDict([])\n",
    "        for i in range(self.num_conv):\n",
    "            conv_repeat_dict[f\"conv_repeat_{i}\"] = nn.Sequential(OrderedDict([\n",
    "                                                    (f'conv_repeat_{i}', nn.Conv1d(512, 512, 31, padding=15*self.dilation, dilation=self.dilation)),\n",
    "                                                    (f'relu_repeat_{i}', nn.LeakyReLU()),\n",
    "                                                    (f'batchnorm_repeat_{i}', nn.BatchNorm1d(512)),\n",
    "                                                    ]))\n",
    "        self.model_conv_repeat = nn.Sequential(conv_repeat_dict)\n",
    "        self.model_body = nn.Sequential(OrderedDict([\n",
    "            ('faltten', Flatten()),\n",
    "            ('dense1', nn.Linear(110*512, 256)),\n",
    "            ('relu5', nn.LeakyReLU()),\n",
    "            ('batchnorm5', nn.BatchNorm1d(256)),\n",
    "            ('dropout1', nn.Dropout(self.dropout)),\n",
    "            ('dense2', nn.Linear(256, 256)),\n",
    "            ('relu6', nn.LeakyReLU()),\n",
    "            ('batchnorm6', nn.BatchNorm1d(256)),\n",
    "            ('dropout1', nn.Dropout(self.dropout))\n",
    "        ]))\n",
    "        self.model_head = nn.Sequential(OrderedDict([\n",
    "            ('dense_head', nn.Linear(256, 1))\n",
    "        ]))\n",
    "\n",
    "    def forward(self, seq):\n",
    "        seq = torch.squeeze(seq, 0)\n",
    "        seq_revcomp = torch.flip(seq.detach().clone(), [1, 2])\n",
    "        y_hat_for = self.model_strand_specific_forward(seq)\n",
    "        y_hat_rev = self.model_strand_specific_reverse(seq_revcomp)\n",
    "        y_hat = torch.cat([y_hat_for, y_hat_rev], dim=1)\n",
    "        y_hat = self.model_body(y_hat)\n",
    "        y_hat = self.model_head(y_hat)\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "class MyLightningCLI(LightningCLI):\n",
    "    def add_arguments_to_parser(self, parser):\n",
    "        parser.add_optimizer_args(torch.optim.Adam)\n",
    "\n",
    "    def after_fit(self):\n",
    "        for cb in self.trainer.callbacks:\n",
    "            if isinstance(cb, ModelCheckpoint):\n",
    "                newname = os.path.join(os.path.dirname(cb.best_model_path), os.path.splitext(os.path.basename(cb.best_model_path))[0] + \"_best.ckpt\")\n",
    "                subprocess.check_call([\"cp\", cb.best_model_path, newname])\n",
    "            break\n",
    "\n",
    "def main():\n",
    "    cli = MyLightningCLI(datamodule_class=DreamChallengeDataModule, auto_registry=True, save_config_overwrite=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting native_pytorch.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile native_pytorch.py\n",
    "\n",
    "import sys\n",
    "import yaml\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "\n",
    "from dataloader import DreamChallengeDataModule\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ConvolutionalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalModel, self).__init__()\n",
    "\n",
    "        self.model_strand_specific_forward = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv1d(4, 256, 31, padding=15)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('conv2', nn.Conv1d(256, 256, 31, padding=15)),\n",
    "            ('relu2', nn.ReLU())\n",
    "        ]))\n",
    "        self.model_strand_specific_reverse = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv1d(4, 256, 31, padding=15)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('conv2', nn.Conv1d(256, 256, 31, padding=15)),\n",
    "            ('relu2', nn.ReLU())\n",
    "        ]))\n",
    "        self.model_body = nn.Sequential(OrderedDict([\n",
    "            ('conv3', nn.Conv1d(512, 256, 31, padding=15)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('conv4', nn.Conv1d(256, 256, 31, padding=15)),\n",
    "            ('relu4', nn.ReLU()),\n",
    "            ('faltten', nn.Flatten()),\n",
    "            ('dense1', nn.Linear(110*256, 256)),\n",
    "            ('relu5', nn.ReLU()),\n",
    "            ('dropout1', nn.Dropout(0.2)),\n",
    "            ('dense2', nn.Linear(256, 256)),\n",
    "            ('relu6', nn.ReLU()),\n",
    "            ('dropout1', nn.Dropout(0.2))\n",
    "        ]))\n",
    "        self.model_head = nn.Sequential(OrderedDict([\n",
    "            ('dense_head', nn.Linear(256, 1))\n",
    "        ]))\n",
    "\n",
    "        self.example_input = torch.zeros(512, 4, 110).index_fill_(1, torch.tensor(2), 1)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        seq_revcomp = torch.flip(seq.detach().clone(), [1, 2])\n",
    "        y_hat_for = self.model_strand_specific_forward(seq)\n",
    "        y_hat_rev = self.model_strand_specific_reverse(seq_revcomp)\n",
    "        y_hat = torch.cat([y_hat_for, y_hat_rev], dim=1)\n",
    "        y_hat = self.model_body(y_hat)\n",
    "        y_hat = self.model_head(y_hat)\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    model = model.to(device)\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    pbar = tqdm(enumerate(dataloader))\n",
    "    for batch, (X, y) in pbar:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        xm.mark_step()\n",
    "\n",
    "        pbar.set_description(f\"Training loss: {loss:>7f}  [{batch:>5d}/{num_batches:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    model = model.to(device)\n",
    "\n",
    "    metric = torchmetrics.MeanSquaredError()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            mse = metric(pred, y)\n",
    "\n",
    "    mse = metric.compute()\n",
    "    print(f\"MSE on all data: {mse}\") \n",
    "\n",
    "def main():\n",
    "    # load config\n",
    "    config = yaml.safe_load(open(sys.argv[1], \"r\"))\n",
    "\n",
    "    device = xm.xla_device()\n",
    "    print(f\"XLA device: {device}\")\n",
    "\n",
    "    model = ConvolutionalModel()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"optimizer\"][\"lr\"])\n",
    "\n",
    "    datamodule = DreamChallengeDataModule(batch_size=config[\"data\"][\"init_args\"][\"batch_size\"], num_workers=config[\"data\"][\"init_args\"][\"num_workers\"])\n",
    "    datamodule.setup()\n",
    "\n",
    "    epochs = 3\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------\")\n",
    "        train_loop(datamodule.train_dataloader(), model.train(), loss_fn, optimizer, device)\n",
    "        test_loop(datamodule.val_dataloader(), model.eval(), loss_fn, device)\n",
    "    print(\"Done!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPU DDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting args_parse.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile args_parse.py\n",
    "\n",
    "# This module cannot import any other PyTorch/XLA module. Only Python core modules.\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "def parse_common_options(datadir=None,\n",
    "                         logdir=None,\n",
    "                         num_cores=None,\n",
    "                         batch_size=128,\n",
    "                         num_epochs=10,\n",
    "                         num_workers=2,\n",
    "                         log_steps=20,\n",
    "                         lr=None,\n",
    "                         momentum=None,\n",
    "                         target_accuracy=None,\n",
    "                         profiler_port=9012,\n",
    "                         opts=None):\n",
    "  parser = argparse.ArgumentParser(add_help=True)\n",
    "  parser.add_argument('--datadir', type=str, default=datadir)\n",
    "  parser.add_argument('--logdir', type=str, default=logdir)\n",
    "  parser.add_argument('--num_cores', type=int, default=num_cores)\n",
    "  parser.add_argument('--batch_size', type=int, default=batch_size)\n",
    "  parser.add_argument('--num_epochs', type=int, default=num_epochs)\n",
    "  parser.add_argument('--num_workers', type=int, default=num_workers)\n",
    "  parser.add_argument('--log_steps', type=int, default=log_steps)\n",
    "  parser.add_argument('--profiler_port', type=int, default=profiler_port)\n",
    "  parser.add_argument('--lr', type=float, default=lr)\n",
    "  parser.add_argument('--momentum', type=float, default=momentum)\n",
    "  parser.add_argument('--target_accuracy', type=float, default=target_accuracy)\n",
    "  parser.add_argument('--drop_last', action='store_true')\n",
    "  parser.add_argument('--fake_data', action='store_true')\n",
    "  parser.add_argument('--tidy', action='store_true')\n",
    "  parser.add_argument('--metrics_debug', action='store_true')\n",
    "  parser.add_argument('--async_closures', action='store_true')\n",
    "  if opts:\n",
    "    for name, aopts in opts:\n",
    "      parser.add_argument(name, **aopts)\n",
    "  args, leftovers = parser.parse_known_args()\n",
    "  sys.argv = [sys.argv[0]] + leftovers\n",
    "  # Setup import folders.\n",
    "  xla_folder = os.path.dirname(os.path.dirname(os.path.abspath(sys.argv[0])))\n",
    "  sys.path.append(os.path.join(os.path.dirname(xla_folder), 'test'))\n",
    "  return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile models.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "class ConvolutionalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalModel, self).__init__()\n",
    "\n",
    "        self.model_strand_specific_forward = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv1d(4, 256, 31, padding=15)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('conv2', nn.Conv1d(256, 256, 31, padding=15)),\n",
    "            ('relu2', nn.ReLU())\n",
    "        ]))\n",
    "        self.model_strand_specific_reverse = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv1d(4, 256, 31, padding=15)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('conv2', nn.Conv1d(256, 256, 31, padding=15)),\n",
    "            ('relu2', nn.ReLU())\n",
    "        ]))\n",
    "        self.model_body = nn.Sequential(OrderedDict([\n",
    "            ('conv3', nn.Conv1d(512, 256, 31, padding=15)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('conv4', nn.Conv1d(256, 256, 31, padding=15)),\n",
    "            ('relu4', nn.ReLU()),\n",
    "            ('faltten', nn.Flatten()),\n",
    "            ('dense1', nn.Linear(110*256, 256)),\n",
    "            ('relu5', nn.ReLU()),\n",
    "            ('dropout1', nn.Dropout(0.2)),\n",
    "            ('dense2', nn.Linear(256, 256)),\n",
    "            ('relu6', nn.ReLU()),\n",
    "            ('dropout1', nn.Dropout(0.2))\n",
    "        ]))\n",
    "        self.model_head = nn.Sequential(OrderedDict([\n",
    "            ('dense_head', nn.Linear(256, 1))\n",
    "        ]))\n",
    "\n",
    "        self.example_input = torch.zeros(512, 4, 110).index_fill_(1, torch.tensor(2), 1)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        seq_revcomp = torch.flip(seq.detach().clone(), [1, 2])\n",
    "        y_hat_for = self.model_strand_specific_forward(seq)\n",
    "        y_hat_rev = self.model_strand_specific_reverse(seq_revcomp)\n",
    "        y_hat = torch.cat([y_hat_for, y_hat_rev], dim=1)\n",
    "        y_hat = self.model_body(y_hat)\n",
    "        y_hat = self.model_head(y_hat)\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "class ConvolutionalModelRegular(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(ConvolutionalModel, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.model_strand_specific_forward = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv1d(4, 256, 31, padding=15)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('batchnorm1', nn.BatchNorm1d(256)),\n",
    "            ('conv2', nn.Conv1d(256, 256, 31, padding=15)),\n",
    "            ('relu2', nn.ReLU())\n",
    "            ('batchnorm2', nn.BatchNorm1d(256))\n",
    "        ]))\n",
    "        self.model_strand_specific_reverse = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv1d(4, 256, 31, padding=15)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('batchnorm1', nn.BatchNorm1d(256)),\n",
    "            ('conv2', nn.Conv1d(256, 256, 31, padding=15)),\n",
    "            ('relu2', nn.ReLU())\n",
    "            ('batchnorm2', nn.BatchNorm1d(256))\n",
    "        ]))\n",
    "        self.model_body = nn.Sequential(OrderedDict([\n",
    "            ('conv3', nn.Conv1d(512, 256, 31, padding=15)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('batchnorm3', nn.BatchNorm1d(256)),\n",
    "            ('conv4', nn.Conv1d(256, 256, 31, padding=15)),\n",
    "            ('relu4', nn.ReLU()),\n",
    "            ('batchnorm4', nn.BatchNorm1d(256)),\n",
    "            ('faltten', nn.Flatten()),\n",
    "            ('dense1', nn.Linear(110*256, 256)),\n",
    "            ('relu5', nn.ReLU()),\n",
    "            ('dropout1', nn.Dropout(self.dropout)),\n",
    "            ('dense2', nn.Linear(256, 256)),\n",
    "            ('relu6', nn.ReLU()),\n",
    "            ('dropout1', nn.Dropout(self.dropout))\n",
    "        ]))\n",
    "        self.model_head = nn.Sequential(OrderedDict([\n",
    "            ('dense_head', nn.Linear(256, 1))\n",
    "        ]))\n",
    "\n",
    "        self.example_input = torch.zeros(512, 4, 110).index_fill_(1, torch.tensor(2), 1)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        seq_revcomp = torch.flip(seq.detach().clone(), [1, 2])\n",
    "        y_hat_for = self.model_strand_specific_forward(seq)\n",
    "        y_hat_rev = self.model_strand_specific_reverse(seq_revcomp)\n",
    "        y_hat = torch.cat([y_hat_for, y_hat_rev], dim=1)\n",
    "        y_hat = self.model_body(y_hat)\n",
    "        y_hat = self.model_head(y_hat)\n",
    "\n",
    "        return y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.arange(10).reshape(2,5))[0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tpu_ddp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tpu_ddp.py\n",
    "\n",
    "import args_parse\n",
    "\n",
    "FLAGS = args_parse.parse_common_options(\n",
    "    log_steps=200,\n",
    "    datadir='./shards/',\n",
    "    logdir='./conv_model/',\n",
    "    batch_size=512,\n",
    "    momentum=0.5,\n",
    "    lr=0.0001,\n",
    "    num_epochs=100,\n",
    "    num_workers=32,\n",
    "    opts=[('--patience', {'type': int, 'default': 5}),\n",
    "          ('--train_epochs', {'type': int, 'default': None})])\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch_xla\n",
    "import torch_xla.debug.metrics as met\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch_xla.test.test_utils as test_utils\n",
    "import webdataset as wds\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dataloader import DreamChallengeDataModule\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import MeanSquaredError\n",
    "\n",
    "import models\n",
    "\n",
    "def _train_update(device, x, loss, tracker, writer):\n",
    "  loss_item = loss.item()\n",
    "  #test_utils.print_training_update(\n",
    "  #    device,\n",
    "  #    x\n",
    "  #    loss_item,\n",
    "  #    tracker.rate(),\n",
    "  #    tracker.global_rate(),\n",
    "  #    summary_writer=writer)\n",
    "  test_utils.write_to_summary(\n",
    "      writer,\n",
    "      dict_to_write={\n",
    "        \"loss\": loss_item\n",
    "      })\n",
    "\n",
    "def train_model(flags, **kwargs):\n",
    "  torch.manual_seed(1)\n",
    "\n",
    "  print(f\"Device {xm.get_ordinal()} in world size of {xm.xrt_world_size()}\")\n",
    "  num_data_instances = xm.xrt_world_size() * flags.num_workers\n",
    "  train_epochs = flags.train_epochs if flags.train_epochs is not None else 5391406//num_data_instances//flags.batch_size\n",
    "  datamodule = DreamChallengeDataModule(data_dir=flags.datadir, train_epochs=train_epochs, batch_size=flags.batch_size, num_workers=flags.num_workers)\n",
    "  datamodule.setup()\n",
    "  train_loader = datamodule.train_dataloader()\n",
    "  val_loader = datamodule.val_dataloader()\n",
    "\n",
    "  # Scale learning rate to num cores\n",
    "  lr = flags.lr * xm.xrt_world_size()\n",
    "\n",
    "  model = models.ConvolutionalModel()\n",
    "  writer = None\n",
    "  if xm.is_master_ordinal():\n",
    "    writer = test_utils.get_summary_writer(flags.logdir)\n",
    "    writer.add_graph(model, model.example_input)\n",
    "  device = xm.xla_device()\n",
    "  model = model.to(device)\n",
    "  #optimizer = optim.SGD(model.parameters(), lr=lr, momentum=flags.momentum)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "  loss_fn = nn.MSELoss()\n",
    "\n",
    "  def train_loop_fn(epoch, loader):\n",
    "    tracker = xm.RateTracker()\n",
    "    model.train()\n",
    "    pbar = tqdm(enumerate(loader))\n",
    "    for step, (data, target) in pbar:\n",
    "      data = torch.squeeze(data, 0)\n",
    "      target = torch.squeeze(target, 0)\n",
    "      optimizer.zero_grad()\n",
    "      output = model(data)\n",
    "      loss = loss_fn(output, target)\n",
    "      loss.backward()\n",
    "      #xm.optimizer_step(optimizer)\n",
    "      xm.reduce_gradients(optimizer)\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1, error_if_nonfinite=True)\n",
    "      optimizer.step()\n",
    "      tracker.add(flags.batch_size)\n",
    "      if xm.is_master_ordinal():\n",
    "        pbar.set_description(\"Loss %s\" % loss.item())\n",
    "        #if step % flags.log_steps == 0:\n",
    "        #  xm.add_step_closure(\n",
    "        #    _train_update,\n",
    "        #    args=(device, step, loss, tracker, writer),\n",
    "        #    run_async=flags.async_closures\n",
    "        #  )\n",
    "    if xm.is_master_ordinal():\n",
    "      torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss.detach().cpu().numpy()\n",
    "      }, os.path.join(flags.logdir, f\"checkpoint-epoch{epoch}.ckpt\"))\n",
    "      \n",
    "  def val_loop_fn(loader):\n",
    "    model.eval()\n",
    "    metrics = MeanSquaredError()\n",
    "    pbar = tqdm(enumerate(loader))\n",
    "    for step, (data, target) in pbar:\n",
    "      data = torch.squeeze(data, 0)\n",
    "      target = torch.squeeze(target, 0)\n",
    "      pred = model(data)\n",
    "      metrics.update(pred, target)\n",
    "      if xm.is_master_ordinal(): \n",
    "        if step == 0:\n",
    "          print(torch.stack([target, pred], 1)[:10])\n",
    "\n",
    "    mse = metrics.compute()  \n",
    "    mse = xm.mesh_reduce('val_mse', mse, np.mean)\n",
    "    return mse\n",
    "\n",
    "  train_device_loader = pl.MpDeviceLoader(train_loader, device)\n",
    "  val_device_loader = pl.MpDeviceLoader(val_loader, device)\n",
    "  # Early stopping\n",
    "  mse, min_mse = 1e3, 1e3\n",
    "  best_epoch = -1\n",
    "  patience = FLAGS.patience\n",
    "  trigger_times = 0\n",
    "  for epoch in range(1, flags.num_epochs + 1):\n",
    "    xm.master_print('Epoch {} train begin {}'.format(epoch, test_utils.now()))\n",
    "    train_loop_fn(epoch, train_device_loader)\n",
    "    xm.master_print('Epoch {} train end {}'.format(epoch, test_utils.now()))\n",
    "\n",
    "    mse = val_loop_fn(val_device_loader)\n",
    "    xm.master_print('Epoch {} end {}, Val MSE={:.2f}'.format(\n",
    "        epoch, test_utils.now(), mse))\n",
    "    test_utils.write_to_summary(\n",
    "        writer,\n",
    "        epoch,\n",
    "        dict_to_write={'MSE/val': mse},\n",
    "        write_xla_metrics=True)\n",
    "    if flags.metrics_debug:\n",
    "      xm.master_print(met.metrics_report())\n",
    "\n",
    "    # Early stopping\n",
    "    if mse > min_mse:\n",
    "        trigger_times += 1\n",
    "        #print('Trigger Times:', trigger_times)\n",
    "        if trigger_times >= patience:\n",
    "            print('Early stopping!\\nStart to test process.')\n",
    "            break\n",
    "    else:\n",
    "        #print('trigger times: 0')\n",
    "        trigger_times = 0\n",
    "\n",
    "        min_mse = mse\n",
    "        best_epoch = epoch\n",
    "\n",
    "  test_utils.close_summary_writer(writer)\n",
    "  xm.master_print(f'Min MSE: {min_mse:.2f} from Epoch {best_epoch}')\n",
    "  if xm.is_master_ordinal(): subprocess.run(['cp', os.path.join(flags.logdir, f\"checkpoint-epoch{best_epoch}.ckpt\"), os.path.join(flags.logdir, f\"checkpoint-epoch{best_epoch}-best.ckpt\")], shell=True)\n",
    "\n",
    "  return min_mse, best_epoch\n",
    "  \n",
    "def _mp_fn(index, flags):\n",
    "  torch.set_default_tensor_type('torch.FloatTensor')\n",
    "  mse, best_epoch = train_model(flags)\n",
    "  if flags.tidy and os.path.isdir(flags.datadir):\n",
    "    shutil.rmtree(flags.datadir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=FLAGS.num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webdataset as wds\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "def npy_decoder(key, value):\n",
    "    if not key.endswith(\".npy\"):\n",
    "        return None\n",
    "    assert isinstance(value, bytes)\n",
    "    return np.load(io.BytesIO(value))\n",
    "\n",
    "dataset_train = wds.DataPipeline(\n",
    "    wds.ResampledShards(\"shards/train-{00..539}.tar\"),\n",
    "    #node_splitter,\n",
    "    #worker_splitter,\n",
    "    wds.tarfile_to_samples(),\n",
    "    wds.decode(npy_decoder),\n",
    "    wds.to_tuple(\"seq.npy\", \"target.npy\"),\n",
    "    wds.batched(512, partial=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq, target in dataset_train: break\n",
    "seq = torch.Tensor(seq)\n",
    "target = torch.Tensor(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "\n",
    "model = models.ConvolutionalModel()\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(seq)\n",
    "    loss = loss_fn(pred, target)\n",
    "    print(loss.item())\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5, error_if_nonfinite=True)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmy5455/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '/home/jmy5455/models.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import importlib\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_xla.core.xla_model as xm\n",
    "model = models.ConvolutionalModel()\n",
    "device = xm.xla_device()\n",
    "model = model.to(device)\n",
    "\n",
    "checkpoint = torch.load(\"./conv_model/v1/checkpoint-epoch6-best.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalModel(\n",
       "  (model_strand_specific_forward): Sequential(\n",
       "    (conv1): Conv1d(4, 256, kernel_size=(31,), stride=(1,), padding=(15,))\n",
       "    (relu1): ReLU()\n",
       "    (conv2): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,))\n",
       "    (relu2): ReLU()\n",
       "  )\n",
       "  (model_strand_specific_reverse): Sequential(\n",
       "    (conv1): Conv1d(4, 256, kernel_size=(31,), stride=(1,), padding=(15,))\n",
       "    (relu1): ReLU()\n",
       "    (conv2): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,))\n",
       "    (relu2): ReLU()\n",
       "  )\n",
       "  (model_body): Sequential(\n",
       "    (conv3): Conv1d(512, 256, kernel_size=(31,), stride=(1,), padding=(15,))\n",
       "    (relu3): ReLU()\n",
       "    (conv4): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,))\n",
       "    (relu4): ReLU()\n",
       "    (faltten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (dense1): Linear(in_features=28160, out_features=256, bias=True)\n",
       "    (relu5): ReLU()\n",
       "    (dropout1): Dropout(p=0.2, inplace=False)\n",
       "    (dense2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (relu6): ReLU()\n",
       "  )\n",
       "  (model_head): Sequential(\n",
       "    (dense_head): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0 in world size of 1\n"
     ]
    }
   ],
   "source": [
    "from dataloader import DreamChallengeDataModule\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "\n",
    "datamodule = DreamChallengeDataModule(data_dir=\"./shards/\", batch_size=128, num_workers=1)\n",
    "datamodule.setup()\n",
    "test_loader = datamodule.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torchmetrics import MeanSquaredError\n",
    "\n",
    "def test_loop_fn(model, loader, device):\n",
    "  model.eval()\n",
    "  metrics = MeanSquaredError()\n",
    "  pbar = tqdm(enumerate(loader))\n",
    "  preds = []; targets = []\n",
    "  for step, (data, target) in pbar:\n",
    "    data = torch.squeeze(data, 0).to(device)\n",
    "    target = torch.squeeze(target, 0).to(device)\n",
    "    pred = model(data)\n",
    "    print(pred)\n",
    "    metrics.update(pred, target)\n",
    "\n",
    "    targets.append(target); preds.append(pred)\n",
    "\n",
    "  mse = metrics.compute()  \n",
    "  return mse, targets, preds\n",
    "\n",
    "def plot_scatter(x, y, lim=20):\n",
    "  fig = plt.figure(figsize=(12, 12))\n",
    "  ax = sns.scatterplot(x=x, y=y)\n",
    "  ax.set_xlim(left=0, right=lim)\n",
    "  ax.set_ylim(bottom=0, right=lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the predictions\n",
    "prediction_test = pd.read_table(\"../logger/predict/ConvReg/model_preds.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "# file available at\n",
    "#https://github.com/de-Boer-Lab/DREAM-2022/blob/main/sample_submission.json\n",
    "def prepare_submission(submission_json, Y_pred):\n",
    "    with open('../DREAM-2022/sample_submission.json', 'r') as f:\n",
    "        ground = json.load(f)\n",
    "\n",
    "    indices = np.array([int(indice) for indice in list(ground.keys())])\n",
    "\n",
    "    PRED_DATA = OrderedDict()\n",
    "    for i in indices:\n",
    "    #Y_pred is an numpy array of dimension (71103,) that contains your\n",
    "    #predictions on the test sequences\n",
    "        PRED_DATA[str(i)] = float(Y_pred[i])\n",
    "\n",
    "    def dump_predictions(prediction_dict, submission_json):\n",
    "        with open(submission_json, 'w') as f:\n",
    "            json.dump(prediction_dict, f)\n",
    "\n",
    "    dump_predictions(PRED_DATA, submission_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_submission(\"ConvReg_v1_pred.json\", prediction_test.to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch_stable')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93d14ffd47093509f56fce87ce8b0ee95afed364b42a5e6da8c370de7719e992"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
